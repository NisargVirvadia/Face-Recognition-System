{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjP67F2S6HTS","outputId":"ebe7ed83-fac9-44d8-a1f0-dcc6afb9cf8a","executionInfo":{"status":"ok","timestamp":1710742380221,"user_tz":420,"elapsed":18015,"user":{"displayName":"Nisarg Jyotin Virvadia","userId":"06291385625915200220"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["root_path = \"/content/drive/MyDrive/Colab Notebooks/COEN240_TA/data\"\n","train_path = root_path + \"/train\"\n","grade_path = root_path + \"/grade\""],"metadata":{"id":"_Emyk11gVfmC","executionInfo":{"status":"ok","timestamp":1710742192730,"user_tz":420,"elapsed":4,"user":{"displayName":"Nisarg Jyotin Virvadia","userId":"06291385625915200220"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["pip install facenet-pytorch\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fApy50qf8xVE","outputId":"363b5219-9737-44d7-fe01-f4b19df4946f","executionInfo":{"status":"ok","timestamp":1710742313923,"user_tz":420,"elapsed":101277,"user":{"displayName":"Nisarg Jyotin Virvadia","userId":"06291385625915200220"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting facenet-pytorch\n","  Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.31.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (0.17.1+cu121)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (9.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2024.2.2)\n","Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchvision->facenet-pytorch) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision->facenet-pytorch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchvision->facenet-pytorch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchvision->facenet-pytorch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, facenet-pytorch\n","Successfully installed facenet-pytorch-2.5.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PuhM5Aar9FF6","outputId":"b514bbed-b960-4b22-be5e-f93da4555d14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["from sklearn.svm import SVC\n","import numpy as np\n","from tqdm import tqdm\n","import torch\n","from facenet_pytorch import InceptionResnetV1\n","import pickle\n","# from dataset import TestDataset\n","from typing import List\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from torchvision.transforms import transforms\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import transforms\n","from PIL import Image, ImageDraw"],"metadata":{"id":"joTkvQcJ6Q6j","executionInfo":{"status":"ok","timestamp":1710742328864,"user_tz":420,"elapsed":9346,"user":{"displayName":"Nisarg Jyotin Virvadia","userId":"06291385625915200220"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"7I7wFaJp6HTU","executionInfo":{"status":"ok","timestamp":1710742331834,"user_tz":420,"elapsed":160,"user":{"displayName":"Nisarg Jyotin Virvadia","userId":"06291385625915200220"}}},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","BATCH_SIZE = 5\n","STARTING_SHAPE = (250, 250)\n","INPUT_SHAPE = (224, 224)\n","\n","LEARNING_RATE = 0.001\n","NUM_EPOCHS = 1\n","\n","TRAINING_DATA_PATH = train_path\n","TRAINING_CSV_FILE = train_path + \"/train.csv\"\n","\n","TESTING_DATA_PATH = grade_path\n","TESTING_CSV_FILE = grade_path + \"/solution.csv\""]},{"cell_type":"code","execution_count":6,"metadata":{"id":"HhZBf2j_6HTV","executionInfo":{"status":"ok","timestamp":1710742333841,"user_tz":420,"elapsed":145,"user":{"displayName":"Nisarg Jyotin Virvadia","userId":"06291385625915200220"}}},"outputs":[],"source":["\n","train_transforms = transforms.Compose([\n","    transforms.Resize(STARTING_SHAPE),\n","    transforms.RandomResizedCrop(INPUT_SHAPE, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n","    transforms.ColorJitter(brightness=0.5),\n","    transforms.RandomRotation(degrees=50),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.GaussianBlur(kernel_size=3),\n","    transforms.ToTensor(),\n","])\n","\n","test_transforms = transforms.Compose([\n","    transforms.Resize(INPUT_SHAPE),\n","    transforms.ToTensor(),\n","])\n","\n","class ClassDataset(Dataset):\n","    def __init__(self, csv_file, root_dir, transform=None):\n","        self.data = pd.read_csv(csv_file)\n","        self.root_dir = Path(root_dir)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.root_dir / self.data.iloc[idx, 0]\n","        image = Image.open(img_name)\n","        label = self.data.iloc[idx, 1]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","class TestDataset(Dataset):\n","    def __init__(self, image_list, transform=test_transforms):\n","        self.image_list = image_list\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_list)\n","\n","    def __getitem__(self, idx):\n","        image = Image.fromarray(self.image_list[idx])\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, \"None\"  # Labels are set as None\n","\n","def get_data_loaders():\n","    train_dataset = ClassDataset(csv_file=TRAINING_CSV_FILE, root_dir=TRAINING_DATA_PATH, transform=train_transforms)\n","    test_dataset = ClassDataset(csv_file=TESTING_CSV_FILE, root_dir=TESTING_DATA_PATH, transform=test_transforms)\n","\n","\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n","    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n","\n","    return train_loader, test_loader\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"vtbgtChq6HTV","executionInfo":{"status":"ok","timestamp":1710742337082,"user_tz":420,"elapsed":359,"user":{"displayName":"Nisarg Jyotin Virvadia","userId":"06291385625915200220"}}},"outputs":[],"source":["\n","class DeepFacedSVM:\n","    def __init__(self, device='cpu'):\n","        self.device = torch.device(device)\n","        self.feature_extractor = InceptionResnetV1(pretrained='vggface2').eval().to(self.device)\n","        self.svm_classifier = SVC(kernel='rbf')\n","\n","    def train(self, train_loader, num_epochs):\n","        train_features, train_labels = self._extract_features(train_loader, num_epochs)\n","        self.svm_classifier.fit(train_features, train_labels)\n","        train_accuracy = self.svm_classifier.score(train_features, train_labels)\n","        print(f\"Train Accuracy: {train_accuracy}\")\n","\n","    def test(self, test_loader):\n","        test_features, test_labels = self._extract_features(test_loader, 1)\n","        test_accuracy = self.svm_classifier.score(test_features, test_labels)\n","        print(f\"Test Accuracy: {test_accuracy}\")\n","\n","    def dump(self, filename):\n","        with open(filename, 'wb') as file:\n","            pickle.dump(self.svm_classifier, file)\n","        print(f\"Model saved as {filename}\")\n","\n","    @classmethod\n","    def load_from_pickle(cls, filename):\n","        with open(filename, 'rb') as file:\n","            svm_classifier = pickle.load(file)\n","        instance = cls()\n","        instance.svm_classifier = svm_classifier\n","        return instance\n","\n","    def _extract_features(self, loader, num_epochs):\n","      features = []\n","      labels = []\n","\n","      for _ in range(num_epochs):\n","          for images, batch_labels in tqdm(loader):\n","              images = images.to(self.device)\n","\n","              with torch.no_grad():\n","                  embeddings = self.feature_extractor(images)\n","\n","              features.append(embeddings.cpu().numpy())\n","              labels.extend(batch_labels.cpu().numpy() if torch.is_tensor(batch_labels) else batch_labels)\n","\n","      features = np.vstack(features)\n","      labels = np.array(labels).reshape(-1, 1)  # Adjust shape if necessary\n","\n","      return features, labels\n","\n","\n","    def inference(self, image_list: List[np.ndarray], filenames: List[str]) -> dict:\n","      inference_dataset: TestDataset = TestDataset(image_list)\n","      inference_loader: DataLoader = DataLoader(inference_dataset, batch_size=1, shuffle=False)\n","      test_features, _ = self._extract_features(inference_loader, 1)\n","      labels: np.ndarray = self.svm_classifier.predict(test_features)\n","\n","        # Generate dictionary of predictions with filenames as keys\n","      predictions = {}\n","      for i, label in enumerate(labels):\n","        predictions[filenames[i]] = label\n","\n","      predictions_df = pd.DataFrame(list(predictions.items()), columns=['filename', 'prediction'])\n","      predictions_df.to_csv('prediction.csv', index=False)\n","      print(predictions_df.head())\n","      predictions_df.to_csv(grade_path+'/prediction.csv', index=False)\n","      return predictions"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"0MTAVG7e6HTW","executionInfo":{"status":"ok","timestamp":1710742339723,"user_tz":420,"elapsed":154,"user":{"displayName":"Nisarg Jyotin Virvadia","userId":"06291385625915200220"}}},"outputs":[],"source":["from pathlib import Path\n","from torchvision.transforms import transforms\n","\n","def save_images_with_labels(images, labels, folder_path, epoch):\n","    folder_path = Path(folder_path)\n","    folder_path.mkdir(parents=True, exist_ok=True)\n","\n","    for i in range(len(images)):\n","        image_name = f'epoch_{epoch}_label_{labels[i]}_image_{i}.png'\n","        image_path = folder_path / image_name\n","        transformed_image = transforms.ToPILImage()(images[i])\n","        transformed_image.save(image_path)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["2964847f885345f7b962f0a3e1b54ce0","a40c09c10ccb4a7e9a198f5d9391b0f2","018b007a6eb94825aab6bb9dd8ec37dc","1b1b4367f96f4874af2489f25f4851ad","7d8f870257d54a4794bb8e85a64b65cf","a4843c146b9e4ab29b35530296a92dcd","675f96fe0d6749f880cea85e0db64eef","ae4dbcd518c04eb8916f13212f757096","2ca288fb157e42b1b6be6cecf30ea3b2","8479cbd9e154470197b38f2174643df7","ea755be621374ab0bec7b4cab8050e06"]},"id":"5nAjbIeE6HTW","outputId":"b1a90e65-0ddd-4eec-b5f1-22a9bffac203","executionInfo":{"status":"ok","timestamp":1710742523762,"user_tz":420,"elapsed":82132,"user":{"displayName":"Nisarg Jyotin Virvadia","userId":"06291385625915200220"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/107M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2964847f885345f7b962f0a3e1b54ce0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|██████████| 86/86 [01:18<00:00,  1.10it/s]\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["Train Accuracy: 0.9836829836829837\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  2.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 1.0\n","Model saved as deepfaced_svm_model.pkl\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["train_loader, test_loader = get_data_loaders()\n","\n","deepfaced_svm = DeepFacedSVM()\n","deepfaced_svm.train(train_loader, NUM_EPOCHS)\n","deepfaced_svm.test(test_loader)\n","deepfaced_svm.dump(\"deepfaced_svm_model.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MqLz_1IT6HTX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rkiWuwBV6HTX","outputId":"8491cf19-1971-4a4b-f3f4-8328e77b67c1","executionInfo":{"status":"ok","timestamp":1710742529582,"user_tz":420,"elapsed":924,"user":{"displayName":"Nisarg Jyotin Virvadia","userId":"06291385625915200220"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  3.24it/s]"]},{"output_type":"stream","name":"stdout","text":["       filename prediction\n","0  0220_18.jpeg  zotaharsh\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import os\n","def load_images_from_folder(folder_path):\n","    images = []\n","\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(('.png', '.jpg', '.jpeg')): # Add more extensions if needed\n","            img_path = os.path.join(folder_path, filename)\n","            try:\n","                img = Image.open(img_path)\n","                img_array = np.array(img)\n","                images.append(img_array)\n","\n","            except Exception as e:\n","                print(f\"Error loading {filename}: {e}\")\n","    return images\n","\n","folder_path = grade_path\n","grade_path1=grade_path + \"/solution.csv\"\n","images = load_images_from_folder(folder_path)\n","image_filenames = [filename for filename in os.listdir(folder_path) if filename.endswith(('.png', '.jpg', '.jpeg'))]\n","deepfaced_svm = DeepFacedSVM.load_from_pickle(\"deepfaced_svm_model.pkl\")\n","predictions = deepfaced_svm.inference(images, image_filenames)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5DJdyPL6HTY","outputId":"5f293131-daa4-4be0-94bb-a9294b68f709","executionInfo":{"status":"ok","timestamp":1710742534197,"user_tz":420,"elapsed":286,"user":{"displayName":"Nisarg Jyotin Virvadia","userId":"06291385625915200220"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction Accuracy: 100.0%\n"]}],"source":["def calculate_accuracy(ground_truths, predictions):\n","    if len(ground_truths) != len(predictions):\n","        raise ValueError(\"The number of predictions does not match the number of ground truths.\")\n","    correct_predictions = 0\n","    for sample_id, ground_truth in ground_truths.items():\n","        if predictions.get(sample_id) == ground_truth:\n","            correct_predictions += 1\n","    return correct_predictions / len(ground_truths)\n","\n","def grade_predictions(predictions, grade_path):\n","    df = pd.read_csv(grade_path1)\n","    ground_truths ={str(key): value for key, value in zip(df['filename'], df['label'])}\n","    df2 = pd. read_csv(grade_path + \"/prediction.csv\")\n","    predictions = dict(zip(df2['filename'], df2['prediction']))\n","    accuracy = calculate_accuracy(ground_truths, predictions)\n","    return accuracy\n","\n","# Example usage\n","\n","accuracy = grade_predictions(predictions,grade_path)\n","print(f\"Prediction Accuracy: {accuracy * 100}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvhgFs2r6HTY"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m4-H55mD6HTY"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"py38","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"2964847f885345f7b962f0a3e1b54ce0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a40c09c10ccb4a7e9a198f5d9391b0f2","IPY_MODEL_018b007a6eb94825aab6bb9dd8ec37dc","IPY_MODEL_1b1b4367f96f4874af2489f25f4851ad"],"layout":"IPY_MODEL_7d8f870257d54a4794bb8e85a64b65cf"}},"a40c09c10ccb4a7e9a198f5d9391b0f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4843c146b9e4ab29b35530296a92dcd","placeholder":"​","style":"IPY_MODEL_675f96fe0d6749f880cea85e0db64eef","value":"100%"}},"018b007a6eb94825aab6bb9dd8ec37dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae4dbcd518c04eb8916f13212f757096","max":111898327,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ca288fb157e42b1b6be6cecf30ea3b2","value":111898327}},"1b1b4367f96f4874af2489f25f4851ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8479cbd9e154470197b38f2174643df7","placeholder":"​","style":"IPY_MODEL_ea755be621374ab0bec7b4cab8050e06","value":" 107M/107M [00:00&lt;00:00, 178MB/s]"}},"7d8f870257d54a4794bb8e85a64b65cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4843c146b9e4ab29b35530296a92dcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"675f96fe0d6749f880cea85e0db64eef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae4dbcd518c04eb8916f13212f757096":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ca288fb157e42b1b6be6cecf30ea3b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8479cbd9e154470197b38f2174643df7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea755be621374ab0bec7b4cab8050e06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}